{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTANT !\n",
    "\n",
    "# In the first order need to set the number of CPU \n",
    "# for calculation before launching (depends on computer's number of cores)\n",
    "n_jobs= 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import glob\n",
    "import joblib\n",
    "import warnings\n",
    "from datetime import date, datetime\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import LeavePGroupsOut\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "import scipy.stats as st\n",
    "\n",
    "from nilearn import image as nli\n",
    "from nilearn import plotting\n",
    "\n",
    "from mne.viz import plot_connectivity_circle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_2(z, control, index):    #age+gender+race/ethn == 4\n",
    "    #z should be a series\n",
    "    #control is a feature table\n",
    "    #index for indexing\n",
    "    \n",
    "    #shrink data to local train index\n",
    "    y = z.reindex(index = index)\n",
    "    X = control.reindex(index = index)\n",
    "\n",
    "    #drop Nan in target and clean this subj from features\n",
    "    y = y.dropna()\n",
    "    X = X.loc[y.index,:]\n",
    "    ind_y = np.array(y.index)\n",
    "    \n",
    "    #Centralize target by y_i-y_mean\n",
    "    y= pd.DataFrame([i-y.mean() for i in y], index=y.index)    \n",
    "    #y_real = y\n",
    "    \n",
    "    #reshaping data\n",
    "    X = X.values\n",
    "    y = y.values.reshape(-1, 1).ravel()\n",
    "    \n",
    "    #fill Nan in X\n",
    "    X = SimpleImputer(strategy='mean').fit_transform(X)\n",
    "    \n",
    "    #Standartize X\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    #Fit to the training set\n",
    "    y_pred = LinearRegression().fit(X, y).predict(X)\n",
    "    \n",
    "    y_res = y - y_pred\n",
    "    \n",
    "    return y_res, ind_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_mov_feature(z, control, mov, index): #age+gender+race/ethn+each specific task movement == 5\n",
    "    #z should be a table of features\n",
    "    #mov should be a series with movements for a specific modality\n",
    "    \n",
    "    #shrink data to local train index\n",
    "    z = z.reindex(index = index)\n",
    "    control = control.reindex(index = index)\n",
    "    mov = mov.reindex(index = index) \n",
    "    ind = z.index\n",
    "    #concal control with mov\n",
    "    cont = control\n",
    "    cont['mov'] = mov\n",
    "    \n",
    "    #loop\n",
    "    dct = {}\n",
    "    col_name = z.columns\n",
    "    for col in col_name:\n",
    "        y = z[col]\n",
    "        X = cont\n",
    "        \n",
    "        #Centralize target by y_i-y_mean\n",
    "        y= pd.DataFrame([i-y.mean() for i in y], index=y.index) \n",
    "        \n",
    "        #reshaping data\n",
    "        X = X.values\n",
    "        y = y.values.reshape(-1, 1).ravel()\n",
    "\n",
    "        #fill Nan in X\n",
    "        X = SimpleImputer(strategy='mean').fit_transform(X)\n",
    "\n",
    "        #Standartize X\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "\n",
    "        #Fit to the training set\n",
    "        y_pred = LinearRegression().fit(X, y).predict(X)\n",
    "\n",
    "        y_res = y - y_pred\n",
    "        \n",
    "        dct[col] = y_res\n",
    "    \n",
    "    df_t = pd.DataFrame(dct, index = ind)\n",
    "    \n",
    "    return df_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path to the tables folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= '/media/DataD800/Alina/retest_set/MLtables/' \n",
    "path_s1200 = '/media/DataD800/Alina/main_set/MLtables/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "#demography\n",
    "demo_retest_test2 = pd.read_csv(path+'demographics_table_new.csv', index_col=0)\n",
    "\n",
    "#targets table\n",
    "targ_retest_test2 = pd.read_csv(path+'cognition_table.csv', index_col=0)\n",
    "\n",
    "#features tables as dictionary\n",
    "features_retest_test2 = {\n",
    "    'emo':pd.read_csv(path+'emo_table.csv', index_col=0),\n",
    "    'gam':pd.read_csv(path+'gam_table.csv', index_col=0),\n",
    "    'lan':pd.read_csv(path+'lan_table.csv', index_col=0),\n",
    "    'mot':pd.read_csv(path+'mot_table.csv', index_col=0),\n",
    "    'rel':pd.read_csv(path+'rel_table.csv', index_col=0),\n",
    "    'soc':pd.read_csv(path+'soc_table.csv', index_col=0),\n",
    "    'wm':pd.read_csv(path+'wm_table.csv', index_col=0),\n",
    "    'cort':pd.read_csv(path+'cort_table.csv', index_col=0),\n",
    "    'subc':pd.read_csv(path+'subc_table.csv', index_col=0),\n",
    "    'surf':pd.read_csv(path+'surf_table.csv', index_col=0),\n",
    "    'rest':pd.read_csv(path+'rest_table_featfiltered.csv', index_col=0),\n",
    "    'VolBrain':pd.read_csv(path+'VolBrain_table.csv', index_col=0)\n",
    "}\n",
    "\n",
    "\n",
    "#table with movements (mean relative displacement Movement_RelativeRMS_mean.txt)\n",
    "movements_retest_test2 = pd.read_csv(path+'movement_table.csv', index_col=0)\n",
    "\n",
    "#create tables with 2 controling parameters: gender and age\n",
    "sex_coded_retest_test2 = pd.Series(LabelEncoder().fit_transform(demo_retest_test2.loc[:,['Gender']]), index=demo_retest_test2.index, name='Gender')\n",
    "control_retest_test2 = pd.concat([sex_coded_retest_test2, demo_retest_test2.loc[:, ['Age_in_Yrs']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "#demography\n",
    "demo_main = pd.read_csv(path_s1200+'demographics_table_new.csv', index_col=0)\n",
    "\n",
    "#targets table\n",
    "targ_main = pd.read_csv(path_s1200+'cognition_table.csv', index_col=0)\n",
    "\n",
    "#features tables as dictionary\n",
    "features_main = {\n",
    "    'emo':pd.read_csv(path_s1200+'emo_table.csv', index_col=0),\n",
    "    'gam':pd.read_csv(path_s1200+'gam_table.csv', index_col=0),\n",
    "    'lan':pd.read_csv(path_s1200+'lan_table.csv', index_col=0),\n",
    "    'mot':pd.read_csv(path_s1200+'mot_table.csv', index_col=0),\n",
    "    'rel':pd.read_csv(path_s1200+'rel_table.csv', index_col=0),\n",
    "    'soc':pd.read_csv(path_s1200+'soc_table.csv', index_col=0),\n",
    "    'wm':pd.read_csv(path_s1200+'wm_table.csv', index_col=0),\n",
    "    'cort':pd.read_csv(path_s1200+'cort_table.csv', index_col=0),\n",
    "    'subc':pd.read_csv(path_s1200+'subc_table.csv', index_col=0),\n",
    "    'surf':pd.read_csv(path_s1200+'surf_table.csv', index_col=0),\n",
    "    'rest':pd.read_csv(path_s1200+'rest_table_featfiltered.csv', index_col=0),\n",
    "    'VolBrain':pd.read_csv(path_s1200+'VolBrain_table.csv', index_col=0)\n",
    "}\n",
    "\n",
    "\n",
    "#table with movements (mean relative displacement Movement_RelativeRMS_mean.txt)\n",
    "movements_main = pd.read_csv(path_s1200+'movement_table.csv', index_col=0)\n",
    "\n",
    "#create tables with 2 controling parameters: gender and age\n",
    "sex_coded_main = pd.Series(LabelEncoder().fit_transform(demo_main.loc[:,['Gender']]), index=demo_main.index, name='Gender')\n",
    "control_main = pd.concat([sex_coded_main, demo_main.loc[:, ['Age_in_Yrs']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shrink tables to same subj numers\n",
    "yy = targ_main['CogTotalComp_Unadj'].dropna()\n",
    "\n",
    "demo_main = demo_main.reindex(index=yy.index)\n",
    "movements_main = movements_main.reindex(index=yy.index)\n",
    "control_main = control_main.reindex(index=yy.index)\n",
    "\n",
    "for key in features_main.keys():\n",
    "    features_main[key] = features_main[key].reindex(index=yy.index)\n",
    "\n",
    "targ_main = targ_main.reindex(index=yy.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shrink tables to same subj numers\n",
    "yy1 = targ_retest_test2['CogTotalComp_Unadj'].dropna()\n",
    "\n",
    "demo_retest_test2 = demo_retest_test2.reindex(index=yy1.index)\n",
    "movements_retest_test2 = movements_retest_test2.reindex(index=yy1.index)\n",
    "control_retest_test2 = control_retest_test2.reindex(index=yy1.index)\n",
    "\n",
    "for key in features_retest_test2.keys():\n",
    "    features_retest_test2[key] = features_retest_test2[key].reindex(index=yy1.index)\n",
    "\n",
    "targ_retest_test2 = targ_retest_test2.reindex(index=yy1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting main ito train and retest_test1\n",
    "\n",
    "demo_retest_test1 = demo_main.loc[demo_retest_test2.index,:]\n",
    "targ_retest_test1 = targ_main.loc[demo_retest_test2.index,:]\n",
    "movements_retest_test1 = movements_main.loc[demo_retest_test2.index,:]\n",
    "control_retest_test1 = control_main.loc[demo_retest_test2.index,:]\n",
    "features_retest_test1 = {}\n",
    "for key in features_main.keys():\n",
    "    features_retest_test1[key] = features_main[key].loc[demo_retest_test2.index,:]\n",
    "\n",
    "\n",
    "demo_train = demo_main.drop(demo_retest_test2.index, axis=0)\n",
    "targ_train = targ_main.drop(demo_retest_test2.index, axis=0)\n",
    "movements_train = movements_main.drop(demo_retest_test2.index, axis=0)\n",
    "control_train = control_main.drop(demo_retest_test2.index, axis=0)\n",
    "features_train = {}\n",
    "for key in features_main.keys():\n",
    "    features_train[key] = features_main[key].drop(demo_retest_test2.index, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(839, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_retest_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_retest_test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Leave-P-groups out based on 8-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CogTotalComp_Unadj\n",
      " \n",
      "started to calculate ML\n",
      "2022-02-04 16:35:50.756374\n",
      " \n",
      "start 1st level  2022-02-04 16:35:50.757056\n",
      " \n",
      "start 2nd level  2022-02-04 16:37:51.379203\n",
      "Checking single ML on test1 data  2022-02-04 16:37:51.379267\n",
      " \n",
      "start 3rd level , retest1 2022-02-04 16:38:51.299840\n",
      "Checking single ML on retest1 data  2022-02-04 16:38:51.299904\n",
      " \n",
      "start 3rd level , retest2 2022-02-04 16:39:06.524629\n",
      "Checking single ML on retest2 data  2022-02-04 16:39:06.525143\n",
      " \n",
      "finished to calculate\n",
      "2022-02-04 16:39:17.758126\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "#for col in targ.columns:\n",
    "col = 'CogTotalComp_Unadj'  \n",
    "y_train = targ_train[col]\n",
    "y_retest_test1 = targ_retest_test1[col]\n",
    "y_retest_test2 = targ_retest_test2[col]\n",
    "\n",
    "\n",
    "print(y_train.name)\n",
    "#nm_f= \n",
    "os.mkdir(path+'output_'+str(y_train.name))\n",
    "path_out = str(path+'output_'+str(y_train.name))\n",
    "\n",
    "\n",
    "#Split to local indexes for main train\n",
    "index_train, index_test = train_test_split(demo_train.index, test_size=0.4, random_state=42)\n",
    "\n",
    "#Local indices\n",
    "index_train = np.array(sorted(index_train), dtype='int') #for training modalities models\n",
    "index_test = np.array(sorted(index_test), dtype='int') #for testing modalities and training second level\n",
    "\n",
    "index_retest_test = np.array(sorted(demo_retest_test2.index), dtype='int')\n",
    "\n",
    "print(' ')\n",
    "print('started to calculate ML')\n",
    "print(datetime.now())\n",
    "print(' ')\n",
    "\n",
    "\n",
    "### 1st level ################################################################################\n",
    "\n",
    "#### Calculations of single ML models on index_train #################################### \n",
    "\n",
    "print('start 1st level ', datetime.now())\n",
    "\n",
    "#control for age+gen and age+gen+mov with sorting to index_train\n",
    "\n",
    "#control y (target) for age+gen\n",
    "p1, p2 = control_2(y_train, control_train, index_train) #where p1 = y_res (residuals), p2 = ind_y (index)\n",
    "y_res1 = pd.Series(p1, index = p2)\n",
    "\n",
    "\n",
    "#control modalities\n",
    "features_res1 = {}\n",
    "for key in features_train.keys():\n",
    "\n",
    "    #controlling tasks for 3 parameter (age+gen+mov)\n",
    "    if key in ['emo', 'gam', 'lan', 'mot', 'rel', 'soc', 'wm']:\n",
    "        features_res1[key] = control_mov_feature(features_train[key], control_train, movements_train[key], y_res1.index)\n",
    "\n",
    "    #controlling the remaining for 2 parameters (age+gen)\n",
    "    if key in ['cort', 'surf', 'subc', 'VolBrain', 'rest']:\n",
    "        d = {}\n",
    "        for col in features_train[key].columns:\n",
    "            p1,p2 = control_2(features_train[key][col], control_train, y_res1.index)\n",
    "            d[col] = p1\n",
    "        df= pd.DataFrame(d, index = p2)\n",
    "        features_res1[key] = df\n",
    "\n",
    "        \n",
    "#save tables\n",
    "y_res1.to_csv(path_out+'/target_y_train1.csv', header=False)\n",
    "\n",
    "\n",
    "for key in features_res1.keys():\n",
    "    features_res1[key].to_csv(path_out+'/'+str(key)+'_train1.csv')\n",
    "    pd.DataFrame((StandardScaler().fit_transform(features_res1[key])), index=features_res1[key].index, columns=features_res1[key].columns).to_csv(path_out+'/'+str(key)+'_train1_std.csv')\n",
    "\n",
    "        \n",
    "        \n",
    "#keep rest residuals as a separate var\n",
    "res_rest1 = features_res1['rest']\n",
    "res_rest1_st = pd.DataFrame((StandardScaler().fit_transform(res_rest1)), index=res_rest1.index, columns=res_rest1.columns)\n",
    "\n",
    "#apply PCA to resting state\n",
    "pca = PCA(n_components=75, random_state=11)\n",
    "pca.fit(res_rest1_st.values)\n",
    "rest_pca1 = pd.DataFrame(pca.transform(res_rest1_st.values), index=res_rest1.index)\n",
    "\n",
    "\n",
    "\n",
    "#save rest pca table\n",
    "rest_pca1.to_csv(path_out+'/rest-pca75_train1.csv')\n",
    "pd.DataFrame((StandardScaler().fit_transform(rest_pca1)), index=rest_pca1.index, columns=rest_pca1.columns).to_csv(path_out+'/rest-pca75_train1_std.csv')\n",
    "\n",
    "\n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 2st level ################################################################################\n",
    "print(' ')\n",
    "print('start 2nd level ', datetime.now())\n",
    "\n",
    "#### L2 Testing single ML models on index_test #############################################\n",
    "\n",
    "print('Checking single ML on test1 data ', datetime.now())\n",
    "\n",
    "#control for age+gen and age+gen+mov with sorting to index_test\n",
    "\n",
    "#control y (target) for age+gen\n",
    "p1, p2 = control_2(y_train, control_train, index_test)\n",
    "y_res2 = pd.Series(p1, index = p2)\n",
    "\n",
    "#control modalities\n",
    "features_res2 = {}\n",
    "for key in features_train.keys():\n",
    "\n",
    "    #controlling tasks for 3 parameter (age+gen+mov)\n",
    "    if key in ['emo', 'gam', 'lan', 'mot', 'rel', 'soc', 'wm']:\n",
    "        features_res2[key] = control_mov_feature(features_train[key], control_train, movements_train[key], y_res2.index)\n",
    "\n",
    "    #controlling the remaining for 2 parameters (age+gen)\n",
    "    if key in ['cort', 'surf', 'subc', 'VolBrain', 'rest']:\n",
    "        d = {}\n",
    "        for col in features_train[key].columns:\n",
    "            p1,p2 = control_2(features_train[key][col], control_train, y_res2.index)\n",
    "            d[col] = p1\n",
    "        df= pd.DataFrame(d, index = p2)\n",
    "        features_res2[key] = df        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#save tables\n",
    "y_res2.to_csv(path_out+'/target_y_train2.csv', header=False)\n",
    "\n",
    "\n",
    "for key in features_res2.keys():\n",
    "    features_res2[key].to_csv(path_out+'/'+str(key)+'_train2.csv')\n",
    "    pd.DataFrame((StandardScaler().fit_transform(features_res2[key])), index=features_res2[key].index, columns=features_res2[key].columns).to_csv(path_out+'/'+str(key)+'_train2_std.csv')        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#keep rest residuals as a separate var\n",
    "res_rest2 = features_res2['rest']\n",
    "res_rest2_st = pd.DataFrame((StandardScaler().fit_transform(res_rest2)), index=res_rest2.index, columns=res_rest2.columns)\n",
    "\n",
    "#apply PCA to resting state\n",
    "rest_pca2 = pd.DataFrame(pca.transform(res_rest2_st.values), index=res_rest2.index)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#save rest pca table\n",
    "rest_pca2.to_csv(path_out+'/rest-pca75_train2.csv')\n",
    "pd.DataFrame((StandardScaler().fit_transform(rest_pca2)), index=rest_pca2.index, columns=rest_pca2.columns).to_csv(path_out+'/rest-pca75_train2_std.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "### 3rd level ################################################################################\n",
    "print(' ')\n",
    "print('start 3rd level , retest1', datetime.now())\n",
    "\n",
    "\n",
    "#### L3 Testing single ML models on retest1 #############################################\n",
    "\n",
    "print('Checking single ML on retest1 data ', datetime.now())\n",
    "\n",
    "#control for age+gen and age+gen+mov with sorting to index_retest_test\n",
    "\n",
    "#control y (target) for age+gen\n",
    "p1, p2 = control_2(y_retest_test1, control_retest_test1, index_retest_test)\n",
    "y_res3 = pd.Series(p1, index = p2)\n",
    "\n",
    "#control modalities\n",
    "features_res3 = {}\n",
    "for key in features_retest_test1.keys():\n",
    "\n",
    "    #controlling tasks for 3 parameter (age+gen+mov)\n",
    "    if key in ['emo', 'gam', 'lan', 'mot', 'rel', 'soc', 'wm']:\n",
    "        features_res3[key] = control_mov_feature(features_retest_test1[key], control_retest_test1, movements_retest_test1[key], y_res3.index)\n",
    "\n",
    "    #controlling the remaining for 2 parameters (age+gen)\n",
    "    if key in ['cort', 'surf', 'subc', 'VolBrain', 'rest']:\n",
    "        d = {}\n",
    "        for col in features_retest_test1[key].columns:\n",
    "            p1,p2 = control_2(features_retest_test1[key][col], control_retest_test1, y_res3.index)\n",
    "            d[col] = p1\n",
    "        df= pd.DataFrame(d, index = p2)\n",
    "        features_res3[key] = df        \n",
    "\n",
    "\n",
    "\n",
    "#save tables\n",
    "y_res3.to_csv(path_out+'/target_y_test1.csv', header=False)\n",
    "\n",
    "\n",
    "for key in features_res3.keys():\n",
    "    features_res3[key].to_csv(path_out+'/'+str(key)+'_test1.csv')\n",
    "    pd.DataFrame((StandardScaler().fit_transform(features_res3[key])), index=features_res3[key].index, columns=features_res3[key].columns).to_csv(path_out+'/'+str(key)+'_test1_std.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#keep rest residuals as a separate var\n",
    "res_rest3 = features_res3['rest']\n",
    "res_rest3_st = pd.DataFrame((StandardScaler().fit_transform(res_rest3)), index=res_rest3.index, columns=res_rest3.columns)\n",
    "\n",
    "#apply PCA to resting state\n",
    "rest_pca3 = pd.DataFrame(pca.transform(res_rest3_st.values), index=res_rest3.index)\n",
    "\n",
    "\n",
    "\n",
    "#save rest pca table\n",
    "rest_pca3.to_csv(path_out+'/rest-pca75_test1.csv')\n",
    "pd.DataFrame((StandardScaler().fit_transform(rest_pca3)), index=rest_pca3.index, columns=rest_pca3.columns).to_csv(path_out+'/rest-pca75_test1_std.csv')\n",
    "\n",
    "       \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 3rd level ################################################################################\n",
    "print(' ')\n",
    "print('start 3rd level , retest2', datetime.now())\n",
    "\n",
    "\n",
    "#### L3 Testing single ML models on retest2 #############################################\n",
    "\n",
    "print('Checking single ML on retest2 data ', datetime.now())\n",
    "\n",
    "#control for age+gen and age+gen+mov with sorting to index_retest_test\n",
    "\n",
    "#control y (target) for age+gen\n",
    "p1, p2 = control_2(y_retest_test2, control_retest_test2, index_retest_test)\n",
    "y_res3 = pd.Series(p1, index = p2)\n",
    "\n",
    "#control modalities\n",
    "features_res3 = {}\n",
    "for key in features_retest_test2.keys():\n",
    "\n",
    "    #controlling tasks for 3 parameter (age+gen+mov)\n",
    "    if key in ['emo', 'gam', 'lan', 'mot', 'rel', 'soc', 'wm']:\n",
    "        features_res3[key] = control_mov_feature(features_retest_test2[key], control_retest_test2, movements_retest_test2[key], y_res3.index)\n",
    "\n",
    "    #controlling the remaining for 2 parameters (age+gen)\n",
    "    if key in ['cort', 'surf', 'subc', 'VolBrain', 'rest']:\n",
    "        d = {}\n",
    "        for col in features_retest_test2[key].columns:\n",
    "            p1,p2 = control_2(features_retest_test2[key][col], control_retest_test2, y_res3.index)\n",
    "            d[col] = p1\n",
    "        df= pd.DataFrame(d, index = p2)\n",
    "        features_res3[key] = df        \n",
    "\n",
    "\n",
    "\n",
    "#save tables\n",
    "y_res3.to_csv(path_out+'/target_y_test2.csv', header=False)\n",
    "\n",
    "\n",
    "for key in features_res3.keys():\n",
    "    features_res3[key].to_csv(path_out+'/'+str(key)+'_test2.csv')\n",
    "    pd.DataFrame((StandardScaler().fit_transform(features_res3[key])), index=features_res3[key].index, columns=features_res3[key].columns).to_csv(path_out+'/'+str(key)+'_test2_std.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#keep rest residuals as a separate var\n",
    "res_rest3 = features_res3['rest']\n",
    "res_rest3_st = pd.DataFrame((StandardScaler().fit_transform(res_rest3)), index=res_rest3.index, columns=res_rest3.columns)\n",
    "\n",
    "#apply PCA to resting state\n",
    "rest_pca3 = pd.DataFrame(pca.transform(res_rest3_st.values), index=res_rest3.index)\n",
    "\n",
    "\n",
    "#save rest pca table\n",
    "rest_pca3.to_csv(path_out+'/rest-pca75_test2.csv')\n",
    "pd.DataFrame((StandardScaler().fit_transform(rest_pca3)), index=rest_pca3.index, columns=rest_pca3.columns).to_csv(path_out+'/rest-pca75_test2_std.csv')\n",
    "\n",
    "\n",
    "     \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(' ')\n",
    "print('finished to calculate')\n",
    "print(datetime.now())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
