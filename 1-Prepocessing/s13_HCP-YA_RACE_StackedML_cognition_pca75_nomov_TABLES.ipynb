{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style='color:red'>  The notebook contains sensitive information. You need to have access to HCP-YA restricted information. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTANT !\n",
    "\n",
    "# In the first order need to set the number of CPU \n",
    "# for calculation before launching (depends on computer's number of cores)\n",
    "n_jobs= 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import glob\n",
    "import joblib\n",
    "import warnings\n",
    "from datetime import date, datetime\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import LeavePGroupsOut\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "import scipy.stats as st\n",
    "\n",
    "from nilearn import image as nli\n",
    "from nilearn import plotting\n",
    "\n",
    "from mne.viz import plot_connectivity_circle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_2(z, control, index):    #age+gender+race/ethn == 4\n",
    "    #z should be a series\n",
    "    #control is a feature table\n",
    "    #index for indexing\n",
    "    \n",
    "    #shrink data to local train index\n",
    "    y = z.reindex(index = index)\n",
    "    X = control.reindex(index = index)\n",
    "\n",
    "    #drop Nan in target and clean this subj from features\n",
    "    y = y.dropna()\n",
    "    X = X.loc[y.index,:]\n",
    "    ind_y = np.array(y.index)\n",
    "    \n",
    "    #Centralize target by y_i-y_mean\n",
    "    y= pd.DataFrame([i-y.mean() for i in y], index=y.index)    \n",
    "    #y_real = y\n",
    "    \n",
    "    #reshaping data\n",
    "    X = X.values\n",
    "    y = y.values.reshape(-1, 1).ravel()\n",
    "    \n",
    "    #fill Nan in X\n",
    "    X = SimpleImputer(strategy='mean').fit_transform(X)\n",
    "    \n",
    "    #Standartize X\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    #Fit to the training set\n",
    "    y_pred = LinearRegression().fit(X, y).predict(X)\n",
    "    \n",
    "    y_res = y - y_pred\n",
    "    \n",
    "    return y_res, ind_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_mov_feature(z, control, mov, index): #age+gender+race/ethn+each specific task movement == 5\n",
    "    #z should be a table of features\n",
    "    #mov should be a series with movements for a specific modality\n",
    "    \n",
    "    #shrink data to local train index\n",
    "    z = z.reindex(index = index)\n",
    "    control = control.reindex(index = index)\n",
    "    mov = mov.reindex(index = index) \n",
    "    ind = z.index\n",
    "    #concal control with mov\n",
    "    cont = control\n",
    "    cont['mov'] = mov\n",
    "    \n",
    "    #loop\n",
    "    dct = {}\n",
    "    col_name = z.columns\n",
    "    for col in col_name:\n",
    "        y = z[col]\n",
    "        X = cont\n",
    "        \n",
    "        #Centralize target by y_i-y_mean\n",
    "        y= pd.DataFrame([i-y.mean() for i in y], index=y.index) \n",
    "        \n",
    "        #reshaping data\n",
    "        X = X.values\n",
    "        y = y.values.reshape(-1, 1).ravel()\n",
    "\n",
    "        #fill Nan in X\n",
    "        X = SimpleImputer(strategy='mean').fit_transform(X)\n",
    "\n",
    "        #Standartize X\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "\n",
    "        #Fit to the training set\n",
    "        y_pred = LinearRegression().fit(X, y).predict(X)\n",
    "\n",
    "        y_res = y - y_pred\n",
    "        \n",
    "        dct[col] = y_res\n",
    "    \n",
    "    df_t = pd.DataFrame(dct, index = ind)\n",
    "    \n",
    "    return df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path to the tables folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/media/DataD800/Alina/main_set/MLtables/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "#demography\n",
    "demo = pd.read_csv(path+'demographics_table_new.csv', index_col=0)\n",
    "\n",
    "#targets table\n",
    "targ = pd.read_csv(path+'cognition_table.csv', index_col=0)\n",
    "\n",
    "#features tables as dictionary\n",
    "features = {\n",
    "    'emo':pd.read_csv(path+'emo_table.csv', index_col=0),\n",
    "    'gam':pd.read_csv(path+'gam_table.csv', index_col=0),\n",
    "    'lan':pd.read_csv(path+'lan_table.csv', index_col=0),\n",
    "    'mot':pd.read_csv(path+'mot_table.csv', index_col=0),\n",
    "    'rel':pd.read_csv(path+'rel_table.csv', index_col=0),\n",
    "    'soc':pd.read_csv(path+'soc_table.csv', index_col=0),\n",
    "    'wm':pd.read_csv(path+'wm_table.csv', index_col=0),\n",
    "    'cort':pd.read_csv(path+'cort_table.csv', index_col=0),\n",
    "    'subc':pd.read_csv(path+'subc_table.csv', index_col=0),\n",
    "    'surf':pd.read_csv(path+'surf_table.csv', index_col=0),\n",
    "    'rest':pd.read_csv(path+'rest_table.csv', index_col=0),\n",
    "    'VolBrain':pd.read_csv(path+'VolBrain_table.csv', index_col=0)\n",
    "\n",
    "}\n",
    "\n",
    "#table with movements (mean relative displacement Movement_RelativeRMS_mean.txt)\n",
    "movements = pd.read_csv(path+'movement_table.csv', index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo['Race_&_Ethnicity'] = pd.Series([i+'_&_'+j for i,j in zip(demo.loc[:,['Race']].values.ravel(), demo.loc[:,['Ethnicity']].values.ravel())], index = demo.index)\n",
    "#display(demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Am. Indian/Alaskan Nat._&amp;_Not Hispanic/Latino</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asian/Nat. Hawaiian/Othr Pacific Is._&amp;_Hispanic/Latino</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asian/Nat. Hawaiian/Othr Pacific Is._&amp;_Not Hispanic/Latino</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asian/Nat. Hawaiian/Othr Pacific Is._&amp;_Unknown or Not Reported</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black or African Am._&amp;_Hispanic/Latino</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black or African Am._&amp;_Not Hispanic/Latino</th>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black or African Am._&amp;_Unknown or Not Reported</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>More than one_&amp;_Hispanic/Latino</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>More than one_&amp;_Not Hispanic/Latino</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown or Not Reported_&amp;_Hispanic/Latino</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown or Not Reported_&amp;_Not Hispanic/Latino</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White_&amp;_Hispanic/Latino</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White_&amp;_Not Hispanic/Latino</th>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White_&amp;_Unknown or Not Reported</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "Am. Indian/Alaskan Nat._&_Not Hispanic/Latino         2\n",
       "Asian/Nat. Hawaiian/Othr Pacific Is._&_Hispanic...    1\n",
       "Asian/Nat. Hawaiian/Othr Pacific Is._&_Not Hisp...   54\n",
       "Asian/Nat. Hawaiian/Othr Pacific Is._&_Unknown ...    2\n",
       "Black or African Am._&_Hispanic/Latino                1\n",
       "Black or African Am._&_Not Hispanic/Latino          117\n",
       "Black or African Am._&_Unknown or Not Reported        1\n",
       "More than one_&_Hispanic/Latino                       7\n",
       "More than one_&_Not Hispanic/Latino                  15\n",
       "Unknown or Not Reported_&_Hispanic/Latino            11\n",
       "Unknown or Not Reported_&_Not Hispanic/Latino         2\n",
       "White_&_Hispanic/Latino                              57\n",
       "White_&_Not Hispanic/Latino                         606\n",
       "White_&_Unknown or Not Reported                       6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Asian/Nat. Hawaiian/Othr Pacific Is._&amp;_Not Hispanic/Latino</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black or African Am._&amp;_Not Hispanic/Latino</th>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White_&amp;_Hispanic/Latino</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White_&amp;_Not Hispanic/Latino</th>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "Asian/Nat. Hawaiian/Othr Pacific Is._&_Not Hisp...   54\n",
       "Black or African Am._&_Not Hispanic/Latino          117\n",
       "White_&_Hispanic/Latino                              57\n",
       "White_&_Not Hispanic/Latino                         606"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "race_var = pd.get_dummies(demo['Race_&_Ethnicity']).sum()\n",
    "race_df = pd.DataFrame(race_var)\n",
    "race_df_cut = race_df[race_df[0]>15]\n",
    "display(race_df)\n",
    "display(race_df_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_rc={}\n",
    "for i in demo['Race_&_Ethnicity'].index:\n",
    "    if demo['Race_&_Ethnicity'][i] not in race_df_cut.index:\n",
    "        dct_rc[i] = 'Other'\n",
    "    else:\n",
    "        dct_rc[i] = demo['Race_&_Ethnicity'][i]\n",
    "df_rc = pd.Series(dct_rc)\n",
    "#display(df_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Asian/Nat. Hawaiian/Othr Pacific Is._&_Not Hispanic/Latino     54\n",
       "Black or African Am._&_Not Hispanic/Latino                    117\n",
       "Other                                                          48\n",
       "White_&_Hispanic/Latino                                        57\n",
       "White_&_Not Hispanic/Latino                                   606\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df_rc).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo['Race_&_Ethnicity2'] = df_rc\n",
    "#display(demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter other tables\n",
    "targ = targ.reindex(index=demo.index)\n",
    "movements = movements.reindex(index=demo.index)\n",
    "for key in features.keys():\n",
    "    features[key] = features[key].reindex(index=demo.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create tables with 4 controling parameters: gender,age, race, ethnicity\n",
    "sex_coded = pd.Series(LabelEncoder().fit_transform(demo.loc[:,['Gender']]), index=demo.index, name='Gender')\n",
    "race_eth_coded = (pd.get_dummies(demo['Race_&_Ethnicity2'])).drop('White_&_Not Hispanic/Latino',axis=1)\n",
    "\n",
    "\n",
    "control = pd.concat([sex_coded, race_eth_coded, demo.loc[:, ['Age_in_Yrs']]], axis=1) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shrink tables to same subj numers\n",
    "yy = targ['CogTotalComp_Unadj'].dropna()\n",
    "\n",
    "demo = demo.reindex(index=yy.index)\n",
    "movements = movements.reindex(index=yy.index)\n",
    "control = control.reindex(index=yy.index)\n",
    "for key in features.keys():\n",
    "    features[key] = features[key].reindex(index=yy.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Leave-P-group out based on 8-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CogTotalComp_Unadj\n",
      " \n",
      "started to calculate the Fold # 0\n",
      "2022-02-01 17:04:50.723997\n",
      " \n",
      "start 1st level  2022-02-01 17:04:50.725568\n",
      "controlling  emo 2022-02-01 17:04:50.826729\n",
      "controlling  gam 2022-02-01 17:04:58.591078\n",
      "controlling  lan 2022-02-01 17:05:06.099061\n",
      "controlling  mot 2022-02-01 17:05:13.680546\n",
      "controlling  rel 2022-02-01 17:05:21.215239\n",
      "controlling  soc 2022-02-01 17:05:28.761048\n",
      "controlling  wm 2022-02-01 17:05:36.216490\n",
      "controlling  cort 2022-02-01 17:05:43.843559\n",
      "controlling  subc 2022-02-01 17:05:46.888576\n",
      "controlling  surf 2022-02-01 17:05:47.275529\n",
      "controlling  rest 2022-02-01 17:05:50.292173\n",
      "controlling  VolBrain 2022-02-01 17:29:05.084033\n",
      " \n",
      "started to calculate the Fold # 1\n",
      "2022-02-01 17:34:07.046201\n",
      " \n",
      "start 1st level  2022-02-01 17:34:07.048128\n",
      "controlling  emo 2022-02-01 17:34:07.086540\n",
      "controlling  gam 2022-02-01 17:34:14.805448\n",
      "controlling  lan 2022-02-01 17:34:22.548005\n",
      "controlling  mot 2022-02-01 17:34:30.262449\n",
      "controlling  rel 2022-02-01 17:34:37.881382\n",
      "controlling  soc 2022-02-01 17:34:45.482869\n",
      "controlling  wm 2022-02-01 17:34:53.188438\n",
      "controlling  cort 2022-02-01 17:35:00.917348\n",
      "controlling  subc 2022-02-01 17:35:04.028282\n",
      "controlling  surf 2022-02-01 17:35:04.422723\n",
      "controlling  rest 2022-02-01 17:35:07.433230\n",
      "controlling  VolBrain 2022-02-01 17:58:53.809995\n",
      " \n",
      "started to calculate the Fold # 2\n",
      "2022-02-01 18:03:22.571428\n",
      " \n",
      "start 1st level  2022-02-01 18:03:22.572916\n",
      "controlling  emo 2022-02-01 18:03:22.600141\n",
      "controlling  gam 2022-02-01 18:03:30.284551\n",
      "controlling  lan 2022-02-01 18:03:37.923256\n",
      "controlling  mot 2022-02-01 18:03:45.669346\n",
      "controlling  rel 2022-02-01 18:03:53.204855\n",
      "controlling  soc 2022-02-01 18:04:00.908326\n",
      "controlling  wm 2022-02-01 18:04:08.504663\n",
      "controlling  cort 2022-02-01 18:04:16.234322\n",
      "controlling  subc 2022-02-01 18:04:19.436610\n",
      "controlling  surf 2022-02-01 18:04:19.837093\n",
      "controlling  rest 2022-02-01 18:04:22.913221\n",
      "controlling  VolBrain 2022-02-01 18:27:44.620180\n",
      " \n",
      "started to calculate the Fold # 3\n",
      "2022-02-01 18:33:03.736089\n",
      " \n",
      "start 1st level  2022-02-01 18:33:03.737926\n",
      "controlling  emo 2022-02-01 18:33:03.771794\n",
      "controlling  gam 2022-02-01 18:33:15.569223\n",
      "controlling  lan 2022-02-01 18:33:27.308835\n",
      "controlling  mot 2022-02-01 18:33:35.399699\n",
      "controlling  rel 2022-02-01 18:33:43.047073\n",
      "controlling  soc 2022-02-01 18:33:50.657802\n",
      "controlling  wm 2022-02-01 18:33:58.279207\n",
      "controlling  cort 2022-02-01 18:34:05.963045\n",
      "controlling  subc 2022-02-01 18:34:09.001051\n",
      "controlling  surf 2022-02-01 18:34:09.388930\n",
      "controlling  rest 2022-02-01 18:34:12.439894\n",
      "controlling  VolBrain 2022-02-01 18:57:19.069952\n",
      " \n",
      "started to calculate the Fold # 4\n",
      "2022-02-01 19:01:50.443172\n",
      " \n",
      "start 1st level  2022-02-01 19:01:50.444735\n",
      "controlling  emo 2022-02-01 19:01:50.465878\n",
      "controlling  gam 2022-02-01 19:01:58.070089\n",
      "controlling  lan 2022-02-01 19:02:05.669014\n",
      "controlling  mot 2022-02-01 19:02:13.240904\n",
      "controlling  rel 2022-02-01 19:02:20.932780\n",
      "controlling  soc 2022-02-01 19:02:28.633626\n",
      "controlling  wm 2022-02-01 19:02:36.245280\n",
      "controlling  cort 2022-02-01 19:02:43.843071\n",
      "controlling  subc 2022-02-01 19:02:46.946399\n",
      "controlling  surf 2022-02-01 19:02:47.339343\n",
      "controlling  rest 2022-02-01 19:02:50.501781\n",
      "controlling  VolBrain 2022-02-01 19:25:44.271232\n",
      " \n",
      "started to calculate the Fold # 5\n",
      "2022-02-01 19:31:12.256471\n",
      " \n",
      "start 1st level  2022-02-01 19:31:12.257962\n",
      "controlling  emo 2022-02-01 19:31:12.278025\n",
      "controlling  gam 2022-02-01 19:31:19.874230\n",
      "controlling  lan 2022-02-01 19:31:27.485645\n",
      "controlling  mot 2022-02-01 19:31:35.149068\n",
      "controlling  rel 2022-02-01 19:31:42.774416\n",
      "controlling  soc 2022-02-01 19:31:50.429625\n",
      "controlling  wm 2022-02-01 19:31:58.110259\n",
      "controlling  cort 2022-02-01 19:32:05.808053\n",
      "controlling  subc 2022-02-01 19:32:08.928461\n",
      "controlling  surf 2022-02-01 19:32:09.317608\n",
      "controlling  rest 2022-02-01 19:32:12.398446\n",
      "controlling  VolBrain 2022-02-01 19:55:16.693689\n",
      " \n",
      "started to calculate the Fold # 6\n",
      "2022-02-01 20:00:02.711515\n",
      " \n",
      "start 1st level  2022-02-01 20:00:02.713010\n",
      "controlling  emo 2022-02-01 20:00:02.735164\n",
      "controlling  gam 2022-02-01 20:00:10.444607\n",
      "controlling  lan 2022-02-01 20:00:18.233985\n",
      "controlling  mot 2022-02-01 20:00:25.946792\n",
      "controlling  rel 2022-02-01 20:00:33.678798\n",
      "controlling  soc 2022-02-01 20:00:41.410472\n",
      "controlling  wm 2022-02-01 20:00:49.058235\n",
      "controlling  cort 2022-02-01 20:00:56.778489\n",
      "controlling  subc 2022-02-01 20:00:59.853911\n",
      "controlling  surf 2022-02-01 20:01:00.250963\n",
      "controlling  rest 2022-02-01 20:01:03.340857\n",
      "controlling  VolBrain 2022-02-01 20:24:10.336034\n",
      " \n",
      "started to calculate the Fold # 7\n",
      "2022-02-01 20:29:13.508504\n",
      " \n",
      "start 1st level  2022-02-01 20:29:13.510072\n",
      "controlling  emo 2022-02-01 20:29:13.532443\n",
      "controlling  gam 2022-02-01 20:29:21.335408\n",
      "controlling  lan 2022-02-01 20:29:29.000001\n",
      "controlling  mot 2022-02-01 20:29:36.734370\n",
      "controlling  rel 2022-02-01 20:29:44.473539\n",
      "controlling  soc 2022-02-01 20:29:52.105563\n",
      "controlling  wm 2022-02-01 20:29:59.755977\n",
      "controlling  cort 2022-02-01 20:30:07.385441\n",
      "controlling  subc 2022-02-01 20:30:10.495371\n",
      "controlling  surf 2022-02-01 20:30:10.887503\n",
      "controlling  rest 2022-02-01 20:30:13.918571\n",
      "controlling  VolBrain 2022-02-01 20:51:03.645533\n",
      " \n",
      "finished the MODEL \n",
      "2022-02-01 20:55:20.241214\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#for col in targ.columns:\n",
    "col = 'CogTotalComp_Unadj'  #the script adapted to be launched on table of target variables. To launch in that way you need to uncomment for loop and comment this row with col variable\n",
    "y = yy#targ[col]\n",
    "\n",
    "print(y.name)\n",
    "\n",
    "###make folder for outputs\n",
    "nmf=path+'output_'+'CogTotalComp_Unadj_RACE_pca75_NoRestMov_newRaceVar_tbls_flat'\n",
    "os.mkdir(nmf)#str(y.name))\n",
    "\n",
    "i=0\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=8)\n",
    "for train_index, test_index in group_kfold.split(demo, groups=demo['Family_ID']): \n",
    "    \n",
    "    #train_index, test_index = group_kfold.split(demo, groups=demo['family_user_def_id']).__next__()\n",
    "    \n",
    "    print(' ')\n",
    "    print('started to calculate the Fold #', i)\n",
    "    print(datetime.now())\n",
    "    print(' ')\n",
    "\n",
    "    ###create directory for specific Fold\n",
    "    os.mkdir(nmf+'/Fold_'+str(i)) \n",
    "    path_out = str(nmf+'/Fold_'+str(i))\n",
    "\n",
    "    ###Global indices\n",
    "    train_index = np.array(demo.iloc[train_index].index) #for training all models\n",
    "    test_index = np.array(demo.iloc[test_index].index) #for final test\n",
    "\n",
    "    ###Split global train_Gindex to local indices\n",
    "    index_train, index_test = train_test_split(train_index, test_size=0.4, random_state=42)\n",
    "\n",
    "    ###Local indices\n",
    "    index_train = np.array(sorted(index_train)) #for training modalities models\n",
    "    index_test = np.array(sorted(index_test)) #for testing modalities and training RF\n",
    "\n",
    "\n",
    "    ### 1st level ################################################################################\n",
    "\n",
    "    #### Calculations of single ML models on index_train #################################### \n",
    "\n",
    "    print('start 1st level ', datetime.now())\n",
    "\n",
    "    #control for age+gen and age+gen+mov with sorting to index_train\n",
    "\n",
    "    #control y (target) for age+gen\n",
    "    p1, p2 = control_2(y, control, train_index) #where p1 = y_res (residuals), p2 = ind_y (index)\n",
    "    y_res1 = pd.Series(p1, index = p2)\n",
    "\n",
    "\n",
    "    #control modalities\n",
    "    features_res1 = {}\n",
    "    for key in features.keys():\n",
    "        print('controlling ', key, datetime.now())\n",
    "\n",
    "        #controlling tasks for 5 parameter (age+gen+race/ethn+mov)\n",
    "        if key in ['emo', 'gam', 'lan', 'mot', 'rel', 'soc', 'wm','0']:\n",
    "            features_res1[key] = control_mov_feature(features[key], control, movements[key], y_res1.index)\n",
    "\n",
    "        #controlling the remaining for 4 parameters (age+gen+race/ethn)\n",
    "        if key in ['cort', 'surf', 'subc', 'VolBrain',  'rest']:\n",
    "            d = {}\n",
    "            for col in features[key].columns:\n",
    "                p1,p2 = control_2(features[key][col], control, y_res1.index)\n",
    "                d[col] = p1\n",
    "            df= pd.DataFrame(d, index = p2)\n",
    "            features_res1[key] = df\n",
    "\n",
    "            \n",
    "    #save tables\n",
    "    y_res1.to_csv(path_out+'/target_y_trainFlat.csv', header=False)\n",
    "    \n",
    "    \n",
    "    for key in features_res1.keys():\n",
    "        features_res1[key].to_csv(path_out+'/'+str(key)+'_trainFlat.csv')\n",
    "        pd.DataFrame((StandardScaler().fit_transform(features_res1[key])), index=features_res1[key].index, columns=features_res1[key].columns).to_csv(path_out+'/'+str(key)+'_trainFlat_std.csv')\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    #keep rest residuals as a separate var\n",
    "    res_rest1 = features_res1['rest']\n",
    "    res_rest1_st = pd.DataFrame((StandardScaler().fit_transform(res_rest1)), index=res_rest1.index, columns=res_rest1.columns)\n",
    "\n",
    "    #apply PCA to resting state\n",
    "    pca = PCA(n_components=75, random_state=11)\n",
    "    pca.fit(res_rest1_st.values)\n",
    "    rest_pca1 = pd.DataFrame(pca.transform(res_rest1_st.values), index=res_rest1.index)\n",
    "\n",
    "    \n",
    "    #save rest pca table\n",
    "    rest_pca1.to_csv(path_out+'/rest-pca75_trainFlat.csv')\n",
    "    pd.DataFrame((StandardScaler().fit_transform(rest_pca1)), index=rest_pca1.index, columns=rest_pca1.columns).to_csv(path_out+'/rest-pca75_trainFlat_std.csv')\n",
    "    \n",
    "\n",
    "\n",
    "    #save models\n",
    "    joblib.dump(pca, (path_out+'/rest_pca_model.sav'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### 2st level ################################################################################\n",
    "    print(' ')\n",
    "    print('start 2nd level ', datetime.now())\n",
    "\n",
    "    #### L2 Testing single ML models on index_test #############################################\n",
    "\n",
    "    print('Checking single ML on test1 data ', datetime.now())\n",
    "\n",
    "    #control for age+gen and age+gen+mov with sorting to index_test\n",
    "\n",
    "    #control y (target) for age+gen\n",
    "    p1, p2 = control_2(y, control, index_test)\n",
    "    y_res2 = pd.Series(p1, index = p2)\n",
    "\n",
    "    #control modalities\n",
    "    features_res2 = {}\n",
    "    for key in features.keys():\n",
    "        print('controlling ', key, datetime.now())\n",
    "\n",
    "        #controlling tasks for 3 parameter (age+gen+mov)\n",
    "        if key in ['emo', 'gam', 'lan', 'mot', 'rel', 'soc', 'wm', '0']:\n",
    "            features_res2[key] = control_mov_feature(features[key], control, movements[key], y_res2.index)\n",
    "            \n",
    "\n",
    "        #controlling the remaining for 2 parameters (age+gen)\n",
    "        if key in ['cort', 'surf', 'subc', 'VolBrain', 'rest']:\n",
    "            d = {}\n",
    "            for col in features[key].columns:\n",
    "                p1,p2 = control_2(features[key][col], control, y_res2.index)\n",
    "                d[col] = p1\n",
    "            df= pd.DataFrame(d, index = p2)\n",
    "            features_res2[key] = df        \n",
    "\n",
    "            \n",
    "    #save tables\n",
    "    y_res2.to_csv(path_out+'/target_y_train2.csv', header=False)\n",
    "    \n",
    "    for key in features_res2.keys():\n",
    "        features_res2[key].to_csv(path_out+'/'+str(key)+'_train2.csv')\n",
    "        pd.DataFrame((StandardScaler().fit_transform(features_res2[key])), index=features_res2[key].index, columns=features_res2[key].columns).to_csv(path_out+'/'+str(key)+'_train2_std.csv')\n",
    "\n",
    "        \n",
    "\n",
    "    #keep rest residuals as a separate var\n",
    "    res_rest2 = features_res2['rest']\n",
    "    res_rest2_st = pd.DataFrame((StandardScaler().fit_transform(res_rest2)), index=res_rest2.index, columns=res_rest2.columns)\n",
    "\n",
    "    #apply PCA to resting state\n",
    "    rest_pca2 = pd.DataFrame(pca.transform(res_rest2_st.values), index=res_rest2.index)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #save rest pca table\n",
    "    rest_pca2.to_csv(path_out+'/rest-pca75_train2.csv')\n",
    "    pd.DataFrame((StandardScaler().fit_transform(rest_pca2)), index=rest_pca2.index, columns=rest_pca2.columns).to_csv(path_out+'/rest-pca75_train2_std.csv')\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ### 3rd level ################################################################################\n",
    "    print(' ')\n",
    "    print('start 3rd level ', datetime.now())\n",
    "\n",
    "\n",
    "    #### L3 Testing single ML models on test_index #############################################\n",
    "\n",
    "    print('Checking single ML on test2 data ', datetime.now())\n",
    "\n",
    "    #control for age+gen and age+gen+mov with sorting to index_test\n",
    "\n",
    "    #control y (target) for age+gen\n",
    "    p1, p2 = control_2(y, control, test_index)\n",
    "    y_res3 = pd.Series(p1, index = p2)\n",
    "\n",
    "    #control modalities\n",
    "    features_res3 = {}\n",
    "    for key in features.keys():\n",
    "        print('controlling ', key, datetime.now())\n",
    "\n",
    "        #controlling tasks for 3 parameter (age+gen+mov)\n",
    "        if key in ['emo', 'gam', 'lan', 'mot', 'rel', 'soc', 'wm', '0']:\n",
    "            features_res3[key] = control_mov_feature(features[key], control, movements[key], y_res3.index)\n",
    "\n",
    "        #controlling the remaining for 2 parameters (age+gen)\n",
    "        if key in ['cort', 'surf', 'subc', 'VolBrain', 'rest']:\n",
    "            d = {}\n",
    "            for col in features[key].columns:\n",
    "                p1,p2 = control_2(features[key][col], control, y_res3.index)\n",
    "                d[col] = p1\n",
    "            df= pd.DataFrame(d, index = p2)\n",
    "            features_res3[key] = df        \n",
    "\n",
    "            \n",
    "            \n",
    "    #save tables\n",
    "    y_res3.to_csv(path_out+'/target_y_test.csv', header=False)\n",
    "    \n",
    "    for key in features_res3.keys():\n",
    "        features_res3[key].to_csv(path_out+'/'+str(key)+'_test.csv')\n",
    "        pd.DataFrame((StandardScaler().fit_transform(features_res3[key])), index=features_res3[key].index, columns=features_res3[key].columns).to_csv(path_out+'/'+str(key)+'_test_std.csv')\n",
    "\n",
    "\n",
    "\n",
    "    #keep rest residuals as a separate var\n",
    "    res_rest3 = features_res3['rest']\n",
    "    res_rest3_st = pd.DataFrame((StandardScaler().fit_transform(res_rest3)), index=res_rest3.index, columns=res_rest3.columns)\n",
    "\n",
    "    #apply PCA to resting state\n",
    "    rest_pca3 = pd.DataFrame(pca.transform(res_rest3_st.values), index=res_rest3.index)\n",
    "\n",
    "    \n",
    "    #save rest pca table\n",
    "    rest_pca3.to_csv(path_out+'/rest-pca75_test.csv')\n",
    "    pd.DataFrame((StandardScaler().fit_transform(rest_pca3)), index=rest_pca3.index, columns=rest_pca3.columns).to_csv(path_out+'/rest-pca75_test_std.csv')\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    print(' ')\n",
    "    print('finished to calculate the Fold #', i)\n",
    "    print(datetime.now())\n",
    "\n",
    "    i+=1\n",
    "\n",
    "print(' ')\n",
    "print('finished the MODEL ')\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
