{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7607bdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23f927ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/media/DataD800/Alina/retest_set/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a957e8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.mkdir(path+'MLtables')\n",
    "path_out = path+'MLtables/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2399e1",
   "metadata": {},
   "source": [
    "### 1. Filtering modality tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e1ab217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load tables\n",
    "features = {\n",
    "    'emo':pd.read_csv(path+'3T_tfMRI_EMOTION_analysis_s2/EMOTION_table_Glasser_FSsubcort.csv', index_col=0),\n",
    "    'gam':pd.read_csv(path+'3T_tfMRI_GAMBLING_analysis_s2/GAMBLING_table_Glasser_FSsubcort.csv', index_col=0),\n",
    "    'lan':pd.read_csv(path+'3T_tfMRI_LANGUAGE_analysis_s2/LANGUAGE_table_Glasser_FSsubcort.csv', index_col=0),\n",
    "    'mot':pd.read_csv(path+'3T_tfMRI_MOTOR_analysis_s2/MOTOR_table_Glasser_FSsubcort.csv', index_col=0),\n",
    "    'rel':pd.read_csv(path+'3T_tfMRI_RELATIONAL_analysis_s2/RELATIONAL_table_Glasser_FSsubcort.csv', index_col=0),\n",
    "    'soc':pd.read_csv(path+'3T_tfMRI_SOCIAL_analysis_s2/SOCIAL_table_Glasser_FSsubcort.csv', index_col=0),\n",
    "    'wm':pd.read_csv(path+'3T_tfMRI_WM_analysis_s2/WM_table_Glasser_FSsubcort.csv', index_col=0),\n",
    "    'cort':pd.read_csv(path+'3T_Structural_preproc_extended/FS_anatomy_cortical_thickness.csv', index_col=0),\n",
    "    'subc':pd.read_csv(path+'3T_Structural_preproc_extended/FS_anatomy_subcortical_volume.csv', index_col=0),\n",
    "    'surf':pd.read_csv(path+'3T_Structural_preproc_extended/FS_anatomy_cortical_area.csv', index_col=0),\n",
    "    'rest':pd.read_csv(path+'3T_rfMRI_REST_fix/group_rest_FC_z.csv', index_col=0),\n",
    "    'VolBrain':pd.read_csv(path+'3T_Structural_preproc_extended/totbrainvol_table.csv', index_col=0),\n",
    "    'movement':pd.read_csv(path+'3T_tfMRI_WM_preproc/all_mods_all_subj_mov.csv', index_col=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d0372730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop subjects with missiong values\n",
    "for key in features.keys():\n",
    "    features[key] = features[key].dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "82477501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 subjects in total\n"
     ]
    }
   ],
   "source": [
    "# Check subjects have all modalities\n",
    "subjects = sorted(list(set(features['emo'].index) & set(features['gam'].index) & set(features['lan'].index) &\n",
    "set(features['mot'].index) & set(features['rel'].index) & set(features['soc'].index) &\n",
    "set(features['wm'].index) & set(features['cort'].index) & set(features['subc'].index) &\n",
    "set(features['surf'].index) & set(features['rest'].index) & set(features['VolBrain'].index) &  set(features['movement'].index)))\n",
    "\n",
    "print(len(subjects), 'subjects in total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d0750031",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter table according list of subjects having all modalities\n",
    "for key in features.keys():\n",
    "    features[key] = features[key].reindex(index=subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028ddb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special chunk for main set only\n",
    "\n",
    "#exclude all subjects with A, B and C QS code\n",
    "df_qs = pd.read_csv(path+'Behavioral_tables/unrestricted.csv', index_col=0)['QC_Issue']\n",
    "df_qs = df_qs.dropna(axis=0)\n",
    "name_to_excl1 = []\n",
    "\n",
    "for ind in df_qs.index:\n",
    "    if 'A' in df_qs.loc[ind]:\n",
    "        name_to_excl1+=[ind]\n",
    "for ind in df_qs.index:\n",
    "    if 'B' in df_qs.loc[ind]:\n",
    "        name_to_excl1+=[ind]\n",
    "#for ind in df_qs.index:\n",
    "#    if 'C' in df_qs.loc[ind]:\n",
    "#        name_to_excl1+=[ind]        \n",
    "        \n",
    "\n",
    "name_to_excl1 = sorted(set(name_to_excl1))\n",
    "print(len(name_to_excl1), 'with A, B issue') #or C \n",
    "#subjects = [s for s in subjects if s not in name_to_excl1]        \n",
    "        \n",
    "\n",
    "#exclude subjects with known major issues from https://wiki.humanconnectome.org/display/PublicData/HCP+Data+Release+Updates%3A+Known+Issues+and+Planned+fixes\n",
    "i=0\n",
    "dct_excl={}\n",
    "for file in glob.glob(path+'QS_issues/*.txt'):\n",
    "    dct_excl[str(i)] = np.loadtxt(file, dtype=int)\n",
    "    i+=1\n",
    "keys = sorted(dct_excl.keys())\n",
    "name_to_excl2 = dct_excl[keys[0]]\n",
    "for key in keys[1:]:\n",
    "    name_to_excl2 = np.append(name_to_excl2, dct_excl[key])\n",
    "\n",
    "name_to_excl2 = sorted(set(name_to_excl2))\n",
    "    \n",
    "print(len(name_to_excl2), 'with major issues')    \n",
    "\n",
    "#subjects = [s for s in subjects if s not in name_to_excl2]     \n",
    "subjects_to_exclude = sorted(set(np.append(name_to_excl1, name_to_excl2)))\n",
    "\n",
    "print(len(subjects_to_exclude), 'subjects need to be excluded')\n",
    "\n",
    "# Filter subjects\n",
    "subjects = [s for s in subjects if s not in subjects_to_exclude]\n",
    "print(len(subjects), 'remains for next retest analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "843559cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 subjects to exclude\n",
      "[433839]\n",
      "35 remains for next retest analysis\n"
     ]
    }
   ],
   "source": [
    "# Special chunk for test-retest set only\n",
    "\n",
    "#exclude all subjects with A, B and C QS code\n",
    "df_qs2 = pd.read_csv(path+'Behavioral_tables/unrestricted.csv', index_col=0)['QC_Issue']\n",
    "df_qs2 = df_qs2.dropna(axis=0)\n",
    "\n",
    "name_to_excl_1 = []\n",
    "\n",
    "for ind in df_qs2.index:\n",
    "    if 'A' in df_qs2.loc[ind]:\n",
    "        name_to_excl_1+=[ind]\n",
    "for ind in df_qs2.index:\n",
    "    if 'B' in df_qs2.loc[ind]:\n",
    "        name_to_excl_1+=[ind]\n",
    "#for ind in df_qs2.index:\n",
    "#    if 'C' in df_qs2.loc[ind]:\n",
    "#        name_to_excl_1+=[ind] \n",
    "\n",
    "name_to_excl_1 = sorted(set(name_to_excl_1))\n",
    "        \n",
    "print(len(name_to_excl_1), 'subjects to exclude')\n",
    "print(name_to_excl_1)\n",
    "\n",
    "# exclude subjs\n",
    "subjects = [s for s in subjects if s not in name_to_excl_1]\n",
    "\n",
    "#check which subjects was used in main set after filtering (write a path to main set file)\n",
    "#means the main set should be processed first\n",
    "main_set_sbj_list = sorted(pd.read_csv('/media/DataD800/Alina/MLtables/cognition_table.csv', index_col=0).index)\n",
    "#and assign them as new list of subjects\n",
    "#subjects = sorted(set(main_set_sbj_list).intersection(set(subjects)))\n",
    "subjects = sorted(set(subjects).intersection(set(main_set_sbj_list)))\n",
    "\n",
    "print(len(subjects), 'remains for next retest analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eaf4c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter table according list of subjects having all modalities\n",
    "for key in features.keys():\n",
    "    features[key] = features[key].reindex(index=subjects)\n",
    "    features[key].to_csv(path_out+str(key)+'_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fbef66",
   "metadata": {},
   "source": [
    "### 2. Creating demographical and cognition tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29bb87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4a14f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load behavioral tables\n",
    "beh_tab_s1200 = pd.read_csv(path+'Behavioral_tables/unrestricted.csv', index_col=0)\n",
    "\n",
    "#choose only cognition columns unadjasted\n",
    "cog_cols = np.array(beh_tab_s1200.columns[114:166])\n",
    "cog_cols = [col for col in cog_cols if '_AgeAdj' not in col]\n",
    "cog_cols = np.append(np.array([cog_cols[-2], cog_cols[-1], cog_cols[-4], cog_cols[-3]], dtype=str), np.array(cog_cols[:-4], dtype=str))\n",
    "\n",
    "#reindex columns in  table\n",
    "cog_tab_s1200 = beh_tab_s1200.reindex(index = subjects, columns = cog_cols) #subjects should be from main set\n",
    "cog_tab_s1200.index.name = None\n",
    "\n",
    "#save\n",
    "cog_tab_s1200.to_csv(path_out+'cognition_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f13532d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retest set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "603c9a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load behavioral tables\n",
    "#write a path to the main set behavioral table folder\n",
    "beh_tab_s1200 = pd.read_csv('/media/DataD800/Alina/Behavioral_tables/unrestricted.csv', index_col=0)\n",
    "beh_tab_retest = pd.read_csv(path+'Behavioral_tables/unrestricted.csv', index_col=0)\n",
    "\n",
    "#choose only cognition columns unadjasted\n",
    "cog_cols = np.array(beh_tab_s1200.columns[114:166])\n",
    "cog_cols = [col for col in cog_cols if '_AgeAdj' not in col]\n",
    "cog_cols = np.append(np.array([cog_cols[-2], cog_cols[-1], cog_cols[-4], cog_cols[-3]], dtype=str), np.array(cog_cols[:-4], dtype=str))\n",
    "\n",
    "#reindex columns in  table\n",
    "cog_tab_retest = beh_tab_retest.reindex(index = subjects, columns = cog_cols)\n",
    "cog_tab_retest.index.name = None\n",
    "\n",
    "#save\n",
    "cog_tab_retest.to_csv(path_out+'cognition_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592310be",
   "metadata": {},
   "source": [
    "###### <span style=\"color:red\">Next table with sensitive information you have to have HCP permission for restricted part !</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "791c5061",
   "metadata": {},
   "outputs": [],
   "source": [
    "beh_tab_s1200_restr = pd.read_csv('/media/DataD800/Alina/Behavioral_tables/RESTRICTED.csv', index_col=0)\n",
    "\n",
    "demo_tab_s1200 = pd.DataFrame()\n",
    "demo_tab_s1200['Gender'] = beh_tab_s1200.loc[subjects, 'Gender']\n",
    "demo_tab_s1200['Age_in_Yrs'] = beh_tab_s1200_restr.loc[subjects, 'Age_in_Yrs']\n",
    "demo_tab_s1200['Family_ID'] = beh_tab_s1200_restr.loc[subjects, 'Family_ID']\n",
    "\n",
    "demo_tab_s1200.to_csv(path_out+'demographics_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1bef02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00268d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1a4407",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
